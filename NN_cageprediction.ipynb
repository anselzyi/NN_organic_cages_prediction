{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "kj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDfDBieoZhQM"
      },
      "source": [
        "# import necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.utils import shuffle \n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "np.random.seed(1)\n"
      ],
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Qs1gwxZhQM"
      },
      "source": [
        "#pd.set_option('display.max_rows',None)\n",
        "#pd.set_option('display.max_columns',None)"
      ],
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LsUwdO_fZhQM",
        "outputId": "4aff13ae-9096-4981-953f-71a79269ff64"
      },
      "source": [
        "# import dataset\n",
        "dataset = pd.read_csv('cages.csv')\n",
        "dataset.head()"
      ],
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>reaction</th>\n",
              "      <th>topology</th>\n",
              "      <th>fingerprint</th>\n",
              "      <th>collapsed</th>\n",
              "      <th>cavity_size</th>\n",
              "      <th>max_diameter</th>\n",
              "      <th>windows</th>\n",
              "      <th>window_diff</th>\n",
              "      <th>window_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thiol2thiol3</td>\n",
              "      <td>FourPlusSix</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.078668</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>thiol2thiol3</td>\n",
              "      <td>FourPlusSix</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.572897</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>thiol2thiol3</td>\n",
              "      <td>FourPlusSix</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.421492</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>thiol2thiol3</td>\n",
              "      <td>FourPlusSix</td>\n",
              "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.049308</td>\n",
              "      <td>25.011154</td>\n",
              "      <td>[2.168335046395502, 1.97799126890146]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>thiol2thiol3</td>\n",
              "      <td>FourPlusSix</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.124412</td>\n",
              "      <td>28.322324</td>\n",
              "      <td>[2.9717479377190696]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   name      reaction  ... window_diff window_std\n",
              "0     0  thiol2thiol3  ...         NaN        NaN\n",
              "1     1  thiol2thiol3  ...         NaN        NaN\n",
              "2     2  thiol2thiol3  ...         NaN        NaN\n",
              "3     3  thiol2thiol3  ...         NaN        NaN\n",
              "4     4  thiol2thiol3  ...         NaN        NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhJx7LZQZhQN"
      },
      "source": [
        "# take out the reaction type 'amine2aldehyde3' and topology type 'FourPlusSix'\n",
        "subdataset = dataset[dataset['reaction'] == 'amine2aldehyde3']\n",
        "subdataset1 = subdataset[subdataset['topology'] == 'FourPlusSix']\n",
        "\n",
        "# eliminate the nan data\n",
        "subdataset2 = subdataset1[subdataset1['collapsed'].notnull()]\n",
        "subdataset3 = subdataset2['fingerprint']\n",
        "\n",
        "\n",
        "# build the overall training set\n",
        "fingerprints =[]\n",
        "single_fingerprint = []\n",
        "\n",
        "# split the string by commas\n",
        "# transfer string to float32\n",
        "for i in range(0,len(subdataset3)):\n",
        "    single_fingerprint = subdataset3.iloc[i,].split(',')\n",
        "    for i in range(0, len(single_fingerprint)):\n",
        "        single_fingerprint[i] = re.findall(\"\\d+\", single_fingerprint[i])\n",
        "        single_fingerprint[i] = [float(x) for x in single_fingerprint[i]]\n",
        "    fingerprints.append(single_fingerprint)\n",
        "\n",
        "fingerprints = np.squeeze(np.array(fingerprints)) # to array and reduce the dimension\n",
        "#print(fingerprints)\n",
        "\n",
        "# build the labels\n",
        "labels_all = subdataset2['collapsed'].values\n",
        "#print(labels)\n"
      ],
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPVKm9ZTZhQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a634a0fa-e0e1-4eb2-a854-28ec0cdaf3bc"
      },
      "source": [
        "num_dataset = len(fingerprints)\n",
        "#print(num_dataset)\n",
        "dataset_index = np.arange(num_dataset) \n",
        "\n",
        "# divide the dataset by labels\n",
        "labels_zero_index = list(np.where(labels_all == 0))\n",
        "labels_one_index = list(np.where(labels_all == 1))\n",
        "#print(np.array(labels_zero_index).size)\n",
        "#print(np.array(labels_one_index).size)\n",
        "\n",
        "fingerprints_zero = fingerprints[labels_zero_index]\n",
        "fingerprints_one = fingerprints[labels_one_index]\n",
        "labels_zero = labels_all[labels_zero_index]\n",
        "labels_one = labels_all[labels_one_index]"
      ],
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu3szmtAZhQO"
      },
      "source": [
        "# shuffle the datasets\n",
        "num_dataset_zero = len(fingerprints_zero)\n",
        "num_dataset_one = len(fingerprints_one)\n",
        "fingerprints_zero_index = np.arange(num_dataset_zero)\n",
        "fingerprints_one_index = np.arange(num_dataset_one)\n",
        "\n",
        "shuffle_fingerprints_zero_index = shuffle(fingerprints_zero_index)\n",
        "shuffle_fingerprints_one_index = shuffle(fingerprints_one_index)"
      ],
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJclcJo9ZhQO"
      },
      "source": [
        "proportion_test = 0.2 # 80% train_dev set, 20% test set\n",
        "num_fingerprints_zero_test = int(proportion_test * num_dataset_zero)\n",
        "num_fingerprints_one_test = int(proportion_test * num_dataset_one)"
      ],
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9fBtE-kZhQO"
      },
      "source": [
        "# build the test set and test label\n",
        "index_fingerprints_zero_test = shuffle_fingerprints_zero_index[:num_fingerprints_zero_test]\n",
        "index_fingerprints_one_test = shuffle_fingerprints_one_index[: num_fingerprints_one_test]\n",
        "\n",
        "fingerprints_zero_test = fingerprints_zero[index_fingerprints_zero_test]\n",
        "fingerprints_one_test = fingerprints_one[index_fingerprints_one_test]\n",
        "label_zero_test = labels_zero[index_fingerprints_zero_test]\n",
        "label_one_test = labels_one[index_fingerprints_one_test]\n",
        "\n",
        "test_set = np.concatenate((fingerprints_zero_test, fingerprints_one_test), axis = 0)\n",
        "test_label = np.concatenate((label_zero_test, label_one_test), axis = 0)\n",
        "#print(test_set.shape)\n",
        "#print(test_label.shape)"
      ],
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjal6eNGZhQO"
      },
      "source": [
        "# build the train_dev set and train_dev label\n",
        "index_train_dev_zero = shuffle_fingerprints_zero_index[num_fingerprints_zero_test:]\n",
        "index_train_dev_one = shuffle_fingerprints_one_index[num_fingerprints_one_test:]\n",
        "fingerprints_zero_train_dev = fingerprints_zero[index_train_dev_zero]\n",
        "fingerprints_one_train_dev = fingerprints_one[index_train_dev_one]\n",
        "label_zero_train_dev = labels_zero[index_train_dev_zero]\n",
        "label_one_train_dev = labels_one[index_train_dev_one]\n",
        "\n",
        "train_dev_set = np.concatenate((fingerprints_zero_train_dev, fingerprints_one_train_dev), axis = 0)\n",
        "train_dev_label = np.concatenate((label_zero_train_dev, label_one_train_dev), axis = 0)\n",
        "#print(train_dev_set.shape)\n",
        "#print(train_dev_label.shape)\n"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGsFNTwLZhQO"
      },
      "source": [
        "# evenly distribute data in test and train_dev set\n",
        "num_test = len(test_set)\n",
        "num_train_dev = len(train_dev_set)\n",
        "test_index = np.arange(num_test)\n",
        "train_dev_index = np.arange(num_train_dev)\n",
        "\n",
        "shuffle_num_test = shuffle(test_index)\n",
        "shuffle_num_train_dev = shuffle(train_dev_index)"
      ],
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpZo28o4ZhQO"
      },
      "source": [
        "# final version of test set and train_dev set\n",
        "test_set = test_set[shuffle_num_test]\n",
        "test_label = test_label[shuffle_num_test][:, np.newaxis]    # shuffle and add one dimension\n",
        "\n",
        "train_dev_set = train_dev_set[shuffle_num_train_dev]\n",
        "train_dev_label = train_dev_label[shuffle_num_train_dev][:, np.newaxis]   # shuffle and add one dimension\n"
      ],
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkdBHPZRZhQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bae8f1e-83bd-439d-de73-888eee6d06a5"
      },
      "source": [
        "# transfer test set and train_dev set from array to tensor\n",
        "test_set = torch.from_numpy(test_set).float()\n",
        "test_label = torch.from_numpy(test_label).float()\n",
        "\n",
        "train_dev_set = torch.from_numpy(train_dev_set).float() \n",
        "train_dev_label = torch.from_numpy(train_dev_label).float()\n",
        "\n",
        "print(test_set.shape)\n",
        "print(test_label.shape)\n",
        "print(train_dev_set.shape)\n",
        "print(train_dev_label.shape)"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([915, 1024])\n",
            "torch.Size([915, 1])\n",
            "torch.Size([3668, 1024])\n",
            "torch.Size([3668, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qoqNcRxZhQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cc7589-229b-432c-a338-7f488592d46d"
      },
      "source": [
        "# construct the neural network\n",
        "class collapse_model(nn.Module):\n",
        "    def __init__(self, x_size, hidden1_size, hidden2_size, hidden3_size, y_size):\n",
        "        super(collapse_model, self).__init__()\n",
        "        self.hidden1 = nn.Linear(x_size, hidden1_size)\n",
        "        #self.batch1 = nn.BatchNorm1d(hidden1_size)   # add batch norm 1\n",
        "        self.hidden2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        #self.batch2 = nn.BatchNorm1d(hidden2_size)  # add batch norm 2\n",
        "        self.hidden3 = nn.Linear(hidden2_size, hidden3_size)\n",
        "        self.predict = nn.Linear(hidden3_size, y_size)\n",
        "    def forward(self, input):\n",
        "        result = self.hidden1(input)\n",
        "        #result = self.batch1(result)   # add batch norm 1\n",
        "        result = F.leaky_relu(result)\n",
        "        result = self.hidden2(result)\n",
        "        #result = self.batch2(result)   # add batch norm 2\n",
        "        result = F.leaky_relu(result)\n",
        "        result = self.hidden3(result)\n",
        "        result = torch.sigmoid(result)\n",
        "        result = self.predict(result)\n",
        "        \n",
        "        return result\n",
        "\n",
        "net = collapse_model(1024, 512, 256, 64, 1)\n",
        "print(net)"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collapse_model(\n",
            "  (hidden1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (hidden2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (hidden3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (predict): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlWTHsYqZhQO"
      },
      "source": [
        "# set optimizer and loss function\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0) # 87.10%\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.001, eps=1e-08, weight_decay=0) # 87.32\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.002, eps=1e-08, weight_decay=0) # 87.21\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.00001, eps=1e-08, weight_decay=0)\n",
        "loss_func = nn.BCEWithLogitsLoss() "
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9wAUbkuUuOE"
      },
      "source": [
        "# use GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dev_set = train_dev_set.to(device)\n",
        "train_dev_label = train_dev_label.to(device)\n",
        "test_set = test_set.to(device)\n",
        "test_label = test_label.to(device)\n",
        "\n",
        "net = net.to(device)\n",
        "loss_func = loss_func.to(device)"
      ],
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2TzChROZhQO"
      },
      "source": [
        "# training and evaluation\n",
        "def evaluate_accuracy(y, pred):\n",
        "    num_set = len(y)\n",
        "\n",
        "    predicted = pred.ge(0.5).view(-1)  \n",
        "    performance = (y == predicted).sum().float() / num_set\n",
        "\n",
        "    \n",
        "    return performance"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLdKpG8PZhQO"
      },
      "source": [
        "def train(net, train_x, train_y, test_x, test_y, loss, num_epochs, optimizer):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        pred = net(train_x)\n",
        "        pred = torch.squeeze(pred)\n",
        "        l = loss_func(pred, train_y)\n",
        "        #optimizer.zero_grad()\n",
        "        #l.backward()\n",
        "        #optimizer.step()\n",
        "        train_loss = l.item()\n",
        "\n",
        "\n",
        "        if epoch == 0 or (epoch + 1) % 100 == 0:\n",
        "            train_acc = evaluate_accuracy(train_y, pred)\n",
        "\n",
        "            test_pred = net(test_x)\n",
        "            test_pred = torch.squeeze(test_pred)\n",
        "            test_loss = loss_func(test_pred, test_y)\n",
        "            test_acc = evaluate_accuracy(test_y, test_pred)\n",
        "            test_loss += test_loss.item()\n",
        "\n",
        "            print('epoch %d ,train loss %.4f'%(epoch + 1,train_loss)+', train accuracy {:.2f}%'.format(train_acc*100))\n",
        "            print('test loss %.4f'% (test_loss)+' test accuracy {:.2f}%'.format(test_acc*100))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        "
      ],
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84sj2YWEZhQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5581791d-2a3e-41fe-cb2b-5f979a6510a2"
      },
      "source": [
        "num_epochs = 3000\n",
        "train(net, train_dev_set, torch.squeeze(train_dev_label), test_set, torch.squeeze(test_label), loss_func, num_epochs, optimizer)"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 ,train loss 0.6979, train accuracy 50.49%\n",
            "test loss 1.3955 test accuracy 50.49%\n",
            "epoch 100 ,train loss 0.6782, train accuracy 50.49%\n",
            "test loss 1.3605 test accuracy 50.49%\n",
            "epoch 200 ,train loss 0.6302, train accuracy 51.36%\n",
            "test loss 1.2739 test accuracy 51.26%\n",
            "epoch 300 ,train loss 0.5417, train accuracy 71.76%\n",
            "test loss 1.1153 test accuracy 72.13%\n",
            "epoch 400 ,train loss 0.4610, train accuracy 80.18%\n",
            "test loss 0.9806 test accuracy 78.47%\n",
            "epoch 500 ,train loss 0.4071, train accuracy 83.29%\n",
            "test loss 0.8931 test accuracy 80.33%\n",
            "epoch 600 ,train loss 0.3737, train accuracy 85.69%\n",
            "test loss 0.8397 test accuracy 81.75%\n",
            "epoch 700 ,train loss 0.3516, train accuracy 86.83%\n",
            "test loss 0.8072 test accuracy 83.72%\n",
            "epoch 800 ,train loss 0.3354, train accuracy 87.43%\n",
            "test loss 0.7865 test accuracy 84.70%\n",
            "epoch 900 ,train loss 0.3220, train accuracy 87.92%\n",
            "test loss 0.7716 test accuracy 84.81%\n",
            "epoch 1000 ,train loss 0.3102, train accuracy 88.50%\n",
            "test loss 0.7601 test accuracy 84.81%\n",
            "epoch 1100 ,train loss 0.2995, train accuracy 88.99%\n",
            "test loss 0.7501 test accuracy 85.25%\n",
            "epoch 1200 ,train loss 0.2893, train accuracy 89.53%\n",
            "test loss 0.7414 test accuracy 85.68%\n",
            "epoch 1300 ,train loss 0.2793, train accuracy 90.10%\n",
            "test loss 0.7333 test accuracy 85.68%\n",
            "epoch 1400 ,train loss 0.2692, train accuracy 90.73%\n",
            "test loss 0.7247 test accuracy 86.01%\n",
            "epoch 1500 ,train loss 0.2589, train accuracy 91.28%\n",
            "test loss 0.7150 test accuracy 85.79%\n",
            "epoch 1600 ,train loss 0.2484, train accuracy 91.79%\n",
            "test loss 0.7044 test accuracy 86.12%\n",
            "epoch 1700 ,train loss 0.2376, train accuracy 92.34%\n",
            "test loss 0.6930 test accuracy 86.56%\n",
            "epoch 1800 ,train loss 0.2260, train accuracy 92.67%\n",
            "test loss 0.6817 test accuracy 86.89%\n",
            "epoch 1900 ,train loss 0.2140, train accuracy 93.62%\n",
            "test loss 0.6723 test accuracy 86.78%\n",
            "epoch 2000 ,train loss 0.2031, train accuracy 94.14%\n",
            "test loss 0.6659 test accuracy 87.32%\n",
            "epoch 2100 ,train loss 0.1929, train accuracy 94.77%\n",
            "test loss 0.6617 test accuracy 87.87%\n",
            "epoch 2200 ,train loss 0.1832, train accuracy 95.50%\n",
            "test loss 0.6598 test accuracy 87.98%\n",
            "epoch 2300 ,train loss 0.1742, train accuracy 96.02%\n",
            "test loss 0.6593 test accuracy 88.31%\n",
            "epoch 2400 ,train loss 0.1657, train accuracy 96.35%\n",
            "test loss 0.6599 test accuracy 87.87%\n",
            "epoch 2500 ,train loss 0.1578, train accuracy 96.78%\n",
            "test loss 0.6613 test accuracy 87.65%\n",
            "epoch 2600 ,train loss 0.1504, train accuracy 97.16%\n",
            "test loss 0.6629 test accuracy 87.65%\n",
            "epoch 2700 ,train loss 0.1434, train accuracy 97.49%\n",
            "test loss 0.6657 test accuracy 87.21%\n",
            "epoch 2800 ,train loss 0.1372, train accuracy 97.66%\n",
            "test loss 0.6713 test accuracy 87.43%\n",
            "epoch 2900 ,train loss 0.1304, train accuracy 97.98%\n",
            "test loss 0.6751 test accuracy 87.32%\n",
            "epoch 3000 ,train loss 0.1250, train accuracy 98.15%\n",
            "test loss 0.6791 test accuracy 87.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fayDCa-RfNTB",
        "outputId": "1132e435-6956-464d-fead-a9223d168418"
      },
      "source": [
        "#evaluation\n",
        "classes = ['collapsed: 0','collapsed: 1']\n",
        "y_pred = net(test_set)\n",
        "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
        "y_test = torch.squeeze(test_label).cpu()\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "collapsed: 0       0.87      0.87      0.87       462\n",
            "collapsed: 1       0.87      0.87      0.87       453\n",
            "\n",
            "    accuracy                           0.87       915\n",
            "   macro avg       0.87      0.87      0.87       915\n",
            "weighted avg       0.87      0.87      0.87       915\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Lrs1GiZvS3"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/drive')"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUBNPdRIZ3VK"
      },
      "source": [
        "#%cd ..\n",
        "#%cd drive/MyDrive/Colab_Notebooks/kimjelfs"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3FXXM05oBDh"
      },
      "source": [
        ""
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2m-izZvbPmC"
      },
      "source": [
        ""
      ],
      "execution_count": 468,
      "outputs": []
    }
  ]
}